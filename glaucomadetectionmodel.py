# -*- coding: utf-8 -*-
"""GlaucomaDetectionModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11vq6Ak0sazHq92f0vm5i9qFRHwOseSET
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import accuracy_score

df = pd.read_csv('Glaucoma.csv')
df.replace('?',-99999,inplace=True)
df.drop(['id'],axis=1,inplace=True)

X=np.array(df.drop(['classes'],axis=1))
y=np.array(df['classes'])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.35, random_state = 42)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_train = pca.fit_transform(X_train)
X_test = pca.fit_transform(X_test)
explained_variance=pca.explained_variance_ratio_

from sklearn.neighbors import KNeighborsClassifier
knn = []
for i in range(1,21):

    classifier = KNeighborsClassifier(n_neighbors=i)
    trained_model=classifier.fit(X_train,y_train)
    trained_model.fit(X_train,y_train )
    y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Initialize knn as an empty list before appending
knn = []

# Compute confusion matrix
cm_KNN = confusion_matrix(y_test, y_pred)
print(cm_KNN)

# Accuracy calculations
print("Accuracy score of train J48:", accuracy_score(y_train, trained_model.predict(X_train)) * 100)
print("Accuracy score of test REPTree:", accuracy_score(y_test, y_pred) * 100)

# Append test accuracy to knn
knn.append(accuracy_score(y_test, y_pred) * 100)

# Check if knn has enough values for plotting
if len(knn) < 20:
    print(f"⚠️ Warning: knn has only {len(knn)} values, expected 20.")

# Ensure knn has 20 values before plotting
while len(knn) < 20:
    knn.append(knn[-1])  # Fill with last accuracy value to avoid errors

# Plot accuracy for different values
plt.figure(figsize=(12, 6))
plt.plot(range(1, 21), knn, color='red', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10)
plt.title('Accuracy for different K Values')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.show()

from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)

trained_model=classifier.fit(X_train,y_train)
trained_model.fit(X_train,y_train )
y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_SVM = confusion_matrix(y_test, y_pred)
print(cm_SVM)
print("Accuracy score of train Random Tree")
print(accuracy_score(y_train, trained_model.predict(X_train))*100)

print("Accuracy score of test Random Tree")
print(accuracy_score(y_test, y_pred)*100)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout

df = pd.read_csv('Glaucoma.csv')
df.replace('?', -99999, inplace=True)
df.drop(['id'], axis=1, inplace=True)

X = df.drop(['classes'], axis=1)
y = df['classes']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_train)
plt.figure(figsize=(8,6))
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y_train)
plt.title('PCA Visualization')
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

def evaluate_model(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{model.__class__.__name__} Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%")
    print(confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))

models = [
    KNeighborsClassifier(n_neighbors=5),
    SVC(kernel='rbf', C=1),
    RandomForestClassifier(n_estimators=100),
    DecisionTreeClassifier(),
    LogisticRegression()
]

for model in models:
    evaluate_model(model, X_train, X_test, y_train, y_test)

param_grid = {'n_neighbors': range(1, 20)}
grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
grid.fit(X_train, y_train)
print("Best K for KNN:", grid.best_params_)

# CNN Model
X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)
X_test_cnn = X_test.reshape(-1, X_test.shape[1], 1)

cnn = Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1], 1)),
    Conv1D(32, 3, activation='relu'),
    MaxPooling1D(2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
cnn.fit(X_train_cnn, y_train, epochs=10, validation_data=(X_test_cnn, y_test))

print("CNN Model Evaluated.")

history = cnn.fit(X_train_cnn, y_train, epochs=10, validation_data=(X_test_cnn, y_test))

# Plot accuracy & loss
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.legend()

plt.show()